{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hugging Face + W&B3",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jb-diplom/jb-thesis/blob/main/NLM-Trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccHJqOajNN7l"
      },
      "source": [
        "#The effect of humour in political messaging: \n",
        "An investigation combining fine-tuned neural language models and social network analysis\n",
        "by\n",
        "Janice Butler: University of Amsterdam, Master Thesis 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKpiNY516JUf"
      },
      "source": [
        "### Introduction\n",
        "This notebook implements the fine-tuning of various neural language models (NLMs) based on a new corpus of annotated humorous texts.\n",
        "Two classifications are made\n",
        "\n",
        "1.   Degree of humour\n",
        "2.   Comic styles\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt71k9Ew6Qp6"
      },
      "source": [
        "### Install dependencies\n",
        "Install the Hugging Face and Weights & Biases libraries, and the dataset and training script for humour fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUP7zxN2NKUi"
      },
      "source": [
        "!pip install transformers -qq           # huggingface framework for loading and training models, preprocessing of data\n",
        "!pip install transformers datasets -qq  # currently transformers datasets --> add own data\n",
        "!pip install wandb -qq                  # for visualization of results on the project dashboard https://wandb.ai/jb-diplom/janice-demo\n",
        "!pip install sentencepiece              # required for deberta\n",
        "# this was the basis for the inital imlementation\n",
        "# !wget https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py -qq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv5DsG_bALsh"
      },
      "source": [
        "## API Key\n",
        "The following call registers this run at Weights and Biases github unless a session is already active.\n",
        "Optionally, we can set environment variables to customize W&B logging. See [documentation](https://docs.wandb.com/library/integrations/huggingface)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3FFmY4JqWdN"
      },
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "# Optional: log both gradients and parameters\n",
        "%env WANDB_WATCH=all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-yWRxcu8kCB"
      },
      "source": [
        "# uncomment to show what gpu is i use\n",
        "#gpu = !nvidia-smi\n",
        "#gpu = '\\n'.join(gpu)\n",
        "#print(gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNWjjJYhNQx3"
      },
      "source": [
        "## Train the model\n",
        "Next, call the downloaded training script [run_glue.py](https://huggingface.co/transformers/examples.html#glue) and see training automatically get tracked to the Weights & Biases dashboard. This script fine-tunes BERT on the Microsoft Research Paraphrase Corpusâ€” pairs of sentences with human annotations indicating whether they are semantically equivalent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pBSRh8kNRBi"
      },
      "source": [
        "%env WANDB_PROJECT=janice-demo\n",
        "%env TASK_NAME=sst2\n",
        "!pwd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',True)\n",
        "!python '/content/gdrive/My Drive/Colab Notebooks/Visualization/run_glue.py' \\\n",
        "  --model_name_or_path microsoft/deberta-base \\\n",
        "  --task_name $TASK_NAME \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --max_seq_length 256 \\\n",
        "  --per_device_train_batch_size 32 \\\n",
        "  --learning_rate 2e-5 \\\n",
        "  --num_train_epochs 4 \\\n",
        "  --output_dir /tmp/sst2-DeBERTa/ \\\n",
        "  --overwrite_output_dir \\\n",
        "  --logging_steps 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFGc9Qs3A7AY"
      },
      "source": [
        "## Visualization of results in dashboard\n",
        "Analyze results (as they happen) on the project dashboard https://wandb.ai/jb-diplom/janice-demo\n"
      ]
    }
  ]
}